{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jacopo.gasparetto/Workspaces/keras-yolo2\")\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Concatenate\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from utils import WeightReader, draw_boxes, decode_netout\n",
    "# from preprocessing import parse_annotation, BatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"+\", \"-\", \"times\", \"div\", \"(\", \")\", \"[\", \"]\", \n",
    "          \"{\", \"}\", \"!\", \",\"]\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3 #0.5\n",
    "NMS_THRESHOLD    = 0.3 #0.45\n",
    "ANCHORS          = [0.48,0.97, 0.65,1.21, 0.89,1.01, 1.14,0.39, 1.20,1.31]\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "TRAIN_DATASET_PATH = os.path.expanduser(\"~/Workspaces/DeepCalculatorBot/ObjectDetection/dataset/train/\")\n",
    "VALID_DATASET_PATH = os.path.expanduser(\"~/Workspaces/DeepCalculatorBot/ObjectDetection/dataset/valid/\")\n",
    "\n",
    "EPOCHS           = 100\n",
    "BATCH_SIZE       = 32\n",
    "WARM_UP_BATCHES  = 3\n",
    "TRUE_BOX_BUFFER  = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(fname):\n",
    "    \"\"\"Parse the input profile\n",
    "    @param fname: input profile path\n",
    "    @return data: a dictionary with user-defined data for training\n",
    "    \"\"\"\n",
    "    with open(fname) as data_file:\n",
    "        data = json.load(data_file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_json(data, fname='./output.json'):\n",
    "    \"\"\"Write data to json\n",
    "    @param data: object to be written\n",
    "    Keyword arguments:\n",
    "    fname  -- output filename (default './output.json')\n",
    "    \"\"\"\n",
    "    with open(fname, 'w') as fp:\n",
    "        json.dump(data, fp, cls=NumpyAwareJSONEncoder)\n",
    "\n",
    "\n",
    "def print_time(t0, s):\n",
    "    \"\"\"Print how much time has been spent\n",
    "    @param t0: previous timestamp\n",
    "    @param s: description of this step\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"%.5f seconds to %s\" % ((time.time() - t0), s))\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some auxiliary variables and the fire module\n",
    "sq1x1  = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu   = \"relu_\"\n",
    "\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1, kernel_initializer='glorot_uniform')(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "    \n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1, kernel_initializer='glorot_uniform')(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "    \n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3, kernel_initializer='glorot_uniform')(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "    \n",
    "    x = concatenate([left, right], axis=3, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "\n",
    "def SqueezeNet_v2(nb_classes, inputs=(416, 416, 3)):\n",
    "    \n",
    "    input_img = Input(shape=inputs)\n",
    "    \n",
    "    x = Convolution2D(96, (7, 7), activation='relu', kernel_initializer='glorot_uniform', strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "    \n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size= (3, 3), strides=(2, 2), name='pool3')(x)\n",
    "    \n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size= (3, 3), strides=(2, 2), name='pool5')(x)\n",
    "    \n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='fire9/dropout')(x)\n",
    "    x = Convolution2D(nb_classes, (1, 1), activation='relu', kernel_initializer='glorot_uniform', padding='valid', name='conv10')(x)\n",
    "\n",
    "    global_avgpool10 = GlobalAveragePooling2D()(x)\n",
    "    softmax = Activation(\"softmax\", name='softmax')(global_avgpool10)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=softmax)\n",
    "  \n",
    "    \n",
    "def SqueezeNet(nb_classes, inputs=(224, 224, 3)):\n",
    "    \"\"\" Keras Implementation of SqueezeNet(arXiv 1602.07360)\n",
    "    @param nb_classes: total number of final categories\n",
    "    Arguments:\n",
    "    inputs -- shape of the input images (channel, cols, rows)\n",
    "    \"\"\"\n",
    "\n",
    "    input_img = Input(shape=inputs)\n",
    "    conv1 = Convolution2D(\n",
    "        96, (7, 7), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        strides=(2, 2), padding='same', name='conv1',\n",
    "        data_format=\"channels_first\")(input_img)\n",
    "    maxpool1 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool1',\n",
    "        data_format=\"channels_first\")(conv1)\n",
    "    fire2_squeeze = Convolution2D(\n",
    "        16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool1)\n",
    "    fire2_expand1 = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand1',\n",
    "        data_format=\"channels_first\")(fire2_squeeze)\n",
    "    fire2_expand2 = Convolution2D(\n",
    "        64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand2',\n",
    "        data_format=\"channels_first\")(fire2_squeeze)\n",
    "    merge2 = Concatenate(axis=1)([fire2_expand1, fire2_expand2])\n",
    "\n",
    "    fire3_squeeze = Convolution2D(\n",
    "        16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_squeeze',\n",
    "        data_format=\"channels_first\")(merge2)\n",
    "    fire3_expand1 = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_expand1',\n",
    "        data_format=\"channels_first\")(fire3_squeeze)\n",
    "    fire3_expand2 = Convolution2D(\n",
    "        64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_expand2',\n",
    "        data_format=\"channels_first\")(fire3_squeeze)\n",
    "    merge3 = Concatenate(axis=1)([fire3_expand1, fire3_expand2])\n",
    "\n",
    "    fire4_squeeze = Convolution2D(\n",
    "        32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_squeeze',\n",
    "        data_format=\"channels_first\")(merge3)\n",
    "    fire4_expand1 = Convolution2D(\n",
    "        128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_expand1',\n",
    "        data_format=\"channels_first\")(fire4_squeeze)\n",
    "    fire4_expand2 = Convolution2D(\n",
    "        128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_expand2',\n",
    "        data_format=\"channels_first\")(fire4_squeeze)\n",
    "    merge4 = Concatenate(axis=1)([fire4_expand1, fire4_expand2])\n",
    "    maxpool4 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool4',\n",
    "        data_format=\"channels_first\")(merge4)\n",
    "\n",
    "    fire5_squeeze = Convolution2D(\n",
    "        32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool4)\n",
    "    fire5_expand1 = Convolution2D(\n",
    "        128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_expand1',\n",
    "        data_format=\"channels_first\")(fire5_squeeze)\n",
    "    fire5_expand2 = Convolution2D(\n",
    "        128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_expand2',\n",
    "        data_format=\"channels_first\")(fire5_squeeze)\n",
    "    merge5 = Concatenate(axis=1)([fire5_expand1, fire5_expand2])\n",
    "\n",
    "    fire6_squeeze = Convolution2D(\n",
    "        48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_squeeze',\n",
    "        data_format=\"channels_first\")(merge5)\n",
    "    fire6_expand1 = Convolution2D(\n",
    "        192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_expand1',\n",
    "        data_format=\"channels_first\")(fire6_squeeze)\n",
    "    fire6_expand2 = Convolution2D(\n",
    "        192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_expand2',\n",
    "        data_format=\"channels_first\")(fire6_squeeze)\n",
    "    merge6 = Concatenate(axis=1)([fire6_expand1, fire6_expand2])\n",
    "\n",
    "    fire7_squeeze = Convolution2D(\n",
    "        48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_squeeze',\n",
    "        data_format=\"channels_first\")(merge6)\n",
    "    fire7_expand1 = Convolution2D(\n",
    "        192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_expand1',\n",
    "        data_format=\"channels_first\")(fire7_squeeze)\n",
    "    fire7_expand2 = Convolution2D(\n",
    "        192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_expand2',\n",
    "        data_format=\"channels_first\")(fire7_squeeze)\n",
    "    merge7 = Concatenate(axis=1)([fire7_expand1, fire7_expand2])\n",
    "\n",
    "    fire8_squeeze = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_squeeze',\n",
    "        data_format=\"channels_first\")(merge7)\n",
    "    fire8_expand1 = Convolution2D(\n",
    "        256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_expand1',\n",
    "        data_format=\"channels_first\")(fire8_squeeze)\n",
    "    fire8_expand2 = Convolution2D(\n",
    "        256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_expand2',\n",
    "        data_format=\"channels_first\")(fire8_squeeze)\n",
    "    merge8 = Concatenate(axis=1)([fire8_expand1, fire8_expand2])\n",
    "\n",
    "    maxpool8 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool8',\n",
    "        data_format=\"channels_first\")(merge8)\n",
    "    fire9_squeeze = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool8)\n",
    "    fire9_expand1 = Convolution2D(\n",
    "        256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_expand1',\n",
    "        data_format=\"channels_first\")(fire9_squeeze)\n",
    "    fire9_expand2 = Convolution2D(\n",
    "        256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_expand2',\n",
    "        data_format=\"channels_first\")(fire9_squeeze)\n",
    "    merge9 = Concatenate(axis=1)([fire9_expand1, fire9_expand2])\n",
    "\n",
    "    fire9_dropout = Dropout(0.5, name='fire9_dropout')(merge9)\n",
    "    conv10 = Convolution2D(\n",
    "        nb_classes, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='valid', name='conv10',\n",
    "        data_format=\"channels_first\")(fire9_dropout)\n",
    "\n",
    "    global_avgpool10 = GlobalAveragePooling2D(data_format='channels_first')(conv10)\n",
    "    softmax = Activation(\"softmax\", name='softmax')(global_avgpool10)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1, 416, 416)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 96, 208, 208) 4800        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 96, 103, 103) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2_squeeze (Conv2D)          (None, 16, 103, 103) 1552        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2_expand1 (Conv2D)          (None, 64, 103, 103) 1088        fire2_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_expand2 (Conv2D)          (None, 64, 103, 103) 9280        fire2_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128, 103, 103 0           fire2_expand1[0][0]              \n",
      "                                                                 fire2_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_squeeze (Conv2D)          (None, 16, 103, 103) 2064        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_expand1 (Conv2D)          (None, 64, 103, 103) 1088        fire3_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_expand2 (Conv2D)          (None, 64, 103, 103) 9280        fire3_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128, 103, 103 0           fire3_expand1[0][0]              \n",
      "                                                                 fire3_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4_squeeze (Conv2D)          (None, 32, 103, 103) 4128        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire4_expand1 (Conv2D)          (None, 128, 103, 103 4224        fire4_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4_expand2 (Conv2D)          (None, 128, 103, 103 36992       fire4_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256, 103, 103 0           fire4_expand1[0][0]              \n",
      "                                                                 fire4_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)         (None, 256, 51, 51)  0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire5_squeeze (Conv2D)          (None, 32, 51, 51)   8224        maxpool4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire5_expand1 (Conv2D)          (None, 128, 51, 51)  4224        fire5_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire5_expand2 (Conv2D)          (None, 128, 51, 51)  36992       fire5_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 256, 51, 51)  0           fire5_expand1[0][0]              \n",
      "                                                                 fire5_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6_squeeze (Conv2D)          (None, 48, 51, 51)   12336       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire6_expand1 (Conv2D)          (None, 192, 51, 51)  9408        fire6_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6_expand2 (Conv2D)          (None, 192, 51, 51)  83136       fire6_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 384, 51, 51)  0           fire6_expand1[0][0]              \n",
      "                                                                 fire6_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7_squeeze (Conv2D)          (None, 48, 51, 51)   18480       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire7_expand1 (Conv2D)          (None, 192, 51, 51)  9408        fire7_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7_expand2 (Conv2D)          (None, 192, 51, 51)  83136       fire7_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 384, 51, 51)  0           fire7_expand1[0][0]              \n",
      "                                                                 fire7_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8_squeeze (Conv2D)          (None, 64, 51, 51)   24640       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire8_expand1 (Conv2D)          (None, 256, 51, 51)  16640       fire8_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8_expand2 (Conv2D)          (None, 256, 51, 51)  147712      fire8_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 512, 51, 51)  0           fire8_expand1[0][0]              \n",
      "                                                                 fire8_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool8 (MaxPooling2D)         (None, 512, 25, 25)  0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire9_squeeze (Conv2D)          (None, 64, 25, 25)   32832       maxpool8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire9_expand1 (Conv2D)          (None, 256, 25, 25)  16640       fire9_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire9_expand2 (Conv2D)          (None, 256, 25, 25)  147712      fire9_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 512, 25, 25)  0           fire9_expand1[0][0]              \n",
      "                                                                 fire9_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire9_dropout (Dropout)         (None, 512, 25, 25)  0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 22, 25, 25)   11286       fire9_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 22)           0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 22)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 737,302\n",
      "Trainable params: 737,302\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SqueezeNet(nb_classes=len(LABELS), inputs=(1, 416, 416))\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 416, 416, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 208, 208, 96) 4800        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 103, 103, 96) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 103, 103, 16) 1552        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 103, 103, 16) 0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 103, 103, 64) 1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 103, 103, 64) 9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 103, 103, 64) 0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 103, 103, 64) 0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 103, 103, 128 0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 103, 103, 16) 2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 103, 103, 16) 0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 103, 103, 64) 1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 103, 103, 64) 9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 103, 103, 64) 0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 103, 103, 64) 0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 103, 103, 128 0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 51, 51, 128)  0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 51, 51, 32)   4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 51, 51, 32)   0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 51, 51, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 51, 51, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 51, 51, 128)  0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 51, 51, 128)  0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 51, 51, 256)  0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 51, 51, 32)   8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 51, 51, 32)   0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 51, 51, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 51, 51, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 51, 51, 128)  0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 51, 51, 128)  0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 51, 51, 256)  0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 25, 25, 256)  0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 25, 25, 48)   12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 25, 25, 48)   0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 25, 25, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 25, 25, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 25, 25, 192)  0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 25, 25, 192)  0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 25, 25, 384)  0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 25, 25, 48)   18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 25, 25, 48)   0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 25, 25, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 25, 25, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 25, 25, 192)  0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 25, 25, 192)  0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 25, 25, 384)  0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 25, 25, 64)   24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 25, 25, 64)   0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 25, 25, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 25, 25, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 25, 25, 256)  0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 25, 25, 256)  0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 25, 25, 512)  0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 25, 25, 64)   32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 25, 25, 64)   0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 25, 25, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 25, 25, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 25, 25, 256)  0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 25, 25, 256)  0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 25, 25, 512)  0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/dropout (Dropout)         (None, 25, 25, 512)  0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 25, 25, 22)   11286       fire9/dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 22)           0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 22)           0           global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 737,302\n",
      "Trainable params: 737,302\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SqueezeNet_v2(nb_classes=len(LABELS), inputs=(416, 416, 1))\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator(data_dir, img_width, img_height, class_mode='categorical', batch_size=32, train_mode=True):\n",
    "   \n",
    "    if train_mode:\n",
    "        datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def val_data_generator(val_data_dir, img_width, img_height,\n",
    "                           class_mode=\"categorical\", batch_size=32):\n",
    "        \"\"\"return ImageDataGenerator for validation data\"\"\"\n",
    "\n",
    "        return train_data_generator(\n",
    "            val_data_dir, img_width, img_height, train_mode=False,\n",
    "            class_mode=class_mode, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129905 images belonging to 23 classes.\n",
      "Found 62145 images belonging to 23 classes.\n",
      "129905\n",
      "62145\n"
     ]
    }
   ],
   "source": [
    "channels = 3\n",
    "sgd = SGD(lr=5e-4, decay=0.0002, momentum=0.9)\n",
    "\n",
    "train_generator = train_data_generator(TRAIN_DATASET_PATH, IMAGE_H, IMAGE_W, batch_size=BATCH_SIZE)\n",
    "val_generator = val_data_generator(VALID_DATASET_PATH, IMAGE_H, IMAGE_W, batch_size=BATCH_SIZE)\n",
    "\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_val_samples = val_generator.samples\n",
    "\n",
    "print(train_generator.samples)\n",
    "print(val_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo.gasparetto/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/home/jacopo.gasparetto/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=4059, epochs=100, validation_steps=62145)`\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected softmax to have shape (22,) but got array with shape (23,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1a74bd268b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model trained in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected softmax to have shape (22,) but got array with shape (23,)"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    nb_epoch=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    nb_val_samples=nb_val_samples\n",
    ")\n",
    "print(\"Model trained in\", time.time() - t0, \"seconds\")\n",
    "model.save_weights('./squeeze_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:28.064549Z",
     "start_time": "2017-11-26T12:34:27.800510Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, BOX, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y     \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    \"\"\"\n",
    "    Debugging code\n",
    "    \"\"\"    \n",
    "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "    total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : TRUE_BOX_BUFFER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/features/\"\n",
    "train_labels_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/labels/\"\n",
    "valid_img_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/features/\"\n",
    "valid_labels_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/labels/\"\n",
    "\n",
    "train_imgs, seen_train_labels = parse_annotation(train_labels_path, train_img_path, labels=LABELS)\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(valid_labels_path, valid_img_path, labels=LABELS)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83, 275, 123, 293,  11],\n",
       "       [ 86, 230, 104, 268,   6],\n",
       "       [115,  64, 147,  96,   2],\n",
       "       [244, 324, 263, 370,  18],\n",
       "       [ 80, 176, 108, 212,   3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.load_annotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup a few callbacks and start the training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:15.714460Z",
     "start_time": "2017-11-26T12:38:15.708674Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T20:38:54.037Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 870s 3s/step - loss: 10.3148 - val_loss: 3.6099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.60992, saving model to weights_coco.h5\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 3.3019 - val_loss: 3.2523\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.60992 to 3.25227, saving model to weights_coco.h5\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 3.9337 - val_loss: 3.1458\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.25227 to 3.14576, saving model to weights_coco.h5\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 3.0432 - val_loss: 2.9946\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.14576 to 2.99463, saving model to weights_coco.h5\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.9614 - val_loss: 2.9306\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.99463 to 2.93059, saving model to weights_coco.h5\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.9124 - val_loss: 2.8945\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.93059 to 2.89448, saving model to weights_coco.h5\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.8790 - val_loss: 2.8564\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.89448 to 2.85638, saving model to weights_coco.h5\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.8492 - val_loss: 2.8326\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.85638 to 2.83258, saving model to weights_coco.h5\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.8268 - val_loss: 2.8166\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.83258 to 2.81663, saving model to weights_coco.h5\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.8082 - val_loss: 2.7917\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.81663 to 2.79174, saving model to weights_coco.h5\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 848s 3s/step - loss: 2.7868 - val_loss: 2.7769\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.79174 to 2.77691, saving model to weights_coco.h5\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 845s 3s/step - loss: 2.7767 - val_loss: 2.7673\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.77691 to 2.76734, saving model to weights_coco.h5\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.7632 - val_loss: 2.7544\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.76734 to 2.75441, saving model to weights_coco.h5\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.7518 - val_loss: 2.7365\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.75441 to 2.73647, saving model to weights_coco.h5\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.7377 - val_loss: 2.7310\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.73647 to 2.73099, saving model to weights_coco.h5\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.7278 - val_loss: 2.7214\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.73099 to 2.72139, saving model to weights_coco.h5\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 2.7148 - val_loss: 2.7117\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.72139 to 2.71165, saving model to weights_coco.h5\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.7115 - val_loss: 2.6997\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.71165 to 2.69968, saving model to weights_coco.h5\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.7008 - val_loss: 2.6927\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.69968 to 2.69267, saving model to weights_coco.h5\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.6918 - val_loss: 2.6835\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.69267 to 2.68350, saving model to weights_coco.h5\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 859s 3s/step - loss: 2.6818 - val_loss: 2.6777\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.68350 to 2.67767, saving model to weights_coco.h5\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 858s 3s/step - loss: 2.6734 - val_loss: 2.6609\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.67767 to 2.66093, saving model to weights_coco.h5\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.6578 - val_loss: 2.6496\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.66093 to 2.64960, saving model to weights_coco.h5\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.6466 - val_loss: 2.6427\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.64960 to 2.64265, saving model to weights_coco.h5\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.6286 - val_loss: 2.6183\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.64265 to 2.61835, saving model to weights_coco.h5\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.6094 - val_loss: 2.6022\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.61835 to 2.60218, saving model to weights_coco.h5\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 842s 3s/step - loss: 2.5817 - val_loss: 2.5576\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.60218 to 2.55755, saving model to weights_coco.h5\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.5485 - val_loss: 2.5271\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.55755 to 2.52714, saving model to weights_coco.h5\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.4999 - val_loss: 2.4679\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.52714 to 2.46795, saving model to weights_coco.h5\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.4479 - val_loss: 2.4120\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.46795 to 2.41197, saving model to weights_coco.h5\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 855s 3s/step - loss: 2.3854 - val_loss: 2.3457\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.41197 to 2.34571, saving model to weights_coco.h5\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 859s 3s/step - loss: 2.2995 - val_loss: 2.2889\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.34571 to 2.28889, saving model to weights_coco.h5\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 848s 3s/step - loss: 2.2186 - val_loss: 2.1674\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.28889 to 2.16736, saving model to weights_coco.h5\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.1481 - val_loss: 2.0938\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.16736 to 2.09384, saving model to weights_coco.h5\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.0524 - val_loss: 2.0315\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.09384 to 2.03147, saving model to weights_coco.h5\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 843s 3s/step - loss: 1.9745 - val_loss: 1.9248\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.03147 to 1.92483, saving model to weights_coco.h5\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 846s 3s/step - loss: 1.8850 - val_loss: 1.8549\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.92483 to 1.85491, saving model to weights_coco.h5\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.7909 - val_loss: 1.7436\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.85491 to 1.74356, saving model to weights_coco.h5\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.7325 - val_loss: 1.6843\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.74356 to 1.68430, saving model to weights_coco.h5\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 843s 3s/step - loss: 1.6335 - val_loss: 1.6073\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.68430 to 1.60725, saving model to weights_coco.h5\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 1.5509 - val_loss: 1.5106\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.60725 to 1.51055, saving model to weights_coco.h5\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 1.4698 - val_loss: 1.4468\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.51055 to 1.44680, saving model to weights_coco.h5\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 1.4228 - val_loss: 1.3858\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.44680 to 1.38582, saving model to weights_coco.h5\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 1.3504 - val_loss: 1.3628\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.38582 to 1.36276, saving model to weights_coco.h5\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.3162 - val_loss: 1.2648\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.36276 to 1.26479, saving model to weights_coco.h5\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 1.2528 - val_loss: 1.2270\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.26479 to 1.22704, saving model to weights_coco.h5\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.2128 - val_loss: 1.1864\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.22704 to 1.18644, saving model to weights_coco.h5\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.1598 - val_loss: 1.1605\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.18644 to 1.16047, saving model to weights_coco.h5\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 1.1296 - val_loss: 1.1270\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.16047 to 1.12698, saving model to weights_coco.h5\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.0778 - val_loss: 1.1063\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.12698 to 1.10630, saving model to weights_coco.h5\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.0669 - val_loss: 1.1260\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 1.0154 - val_loss: 1.0176\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.10630 to 1.01762, saving model to weights_coco.h5\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 0.9857 - val_loss: 1.0172\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.01762 to 1.01721, saving model to weights_coco.h5\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 127.9096 - val_loss: nan\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 855s 3s/step - loss: 2.8633 - val_loss: 5.1818\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c28039f60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = os.path.expanduser('~/Workspaces/DeepCalculatorBot/ObjectDetection/logs/')\n",
    "tb_counter  = len([log for log in os.listdir(log_dir) if 'coco_' in log]) + 1\n",
    "tensorboard = TensorBoard(log_dir=os.path.expanduser(log_dir) + 'coco_' + '_' + str(tb_counter), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_images=True)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform detection on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:49.271978Z",
     "start_time": "2017-11-22T14:07:49.268999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:19:07.263359",
     "start_time": "2018-04-04T00:19:05.658285"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 960)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c6d675da089a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image = cv2.imread('/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/fake_dataset/features/52.png')\n",
    "image = cv2.imread('/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/test_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "print(image.shape)\n",
    "input_image = cv2.resize(image, (416, 416))\n",
    "input_image = input_image / 255.\n",
    "input_image = input_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "netout = model.predict([input_image, dummy_array])\n",
    "boxes = decode_netout(netout[0], \n",
    "                      obj_threshold=OBJ_THRESHOLD,\n",
    "                      nms_threshold=NMS_THRESHOLD,\n",
    "                      anchors=ANCHORS, \n",
    "                      nb_class=CLASS)\n",
    "image = draw_boxes(image, boxes, labels=LABELS)\n",
    "\n",
    "plt.imshow(image[:,:,::-1]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
