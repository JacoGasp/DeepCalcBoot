{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jacopo.gasparetto/Workspaces/keras-yolo2\")\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import WeightReader, draw_boxes, decode_netout\n",
    "from preprocessing import parse_annotation, BatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"+\", \"-\", \"times\", \"div\", \"(\", \")\", \"[\", \"]\", \n",
    "          \"{\", \"}\", \"!\", \",\"]\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3 #0.5\n",
    "NMS_THRESHOLD    = 0.3 #0.45\n",
    "ANCHORS          = [0.48,0.97, 0.65,1.21, 0.89,1.01, 1.14,0.39, 1.20,1.31]\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 32\n",
    "WARM_UP_BATCHES  = 3\n",
    "TRUE_BOX_BUFFER  = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to implement the organization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 13, 13, 1280) 0           lambda_1[0][0]                   \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 135)  138375      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 27 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1, 1, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 13, 13, 5, 27 0           reshape_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,686,311\n",
      "Trainable params: 50,665,639\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained weights\n",
    "Load the weights originally provided by YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader = WeightReader(\"/home/jacopo.gasparetto/Workspaces/keras-yolo2/full_yolo_backend.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "nb_conv = 23\n",
    "\n",
    "for i in range(1, nb_conv + 1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        \n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "        beta  = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean  = weight_reader.read_bytes(size)\n",
    "        var   = weight_reader.read_bytes(size)\n",
    "\n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "        \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2,3,1,0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:28.064549Z",
     "start_time": "2017-11-26T12:34:27.800510Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, BOX, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y     \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    \"\"\"\n",
    "    Debugging code\n",
    "    \"\"\"    \n",
    "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "    total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : TRUE_BOX_BUFFER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/features/\"\n",
    "train_labels_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/labels/\"\n",
    "valid_img_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/features/\"\n",
    "valid_labels_path = \"/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/xml_dataset/labels/\"\n",
    "\n",
    "train_imgs, seen_train_labels = parse_annotation(train_labels_path, train_img_path, labels=LABELS)\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(valid_labels_path, valid_img_path, labels=LABELS)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83, 275, 123, 293,  11],\n",
       "       [ 86, 230, 104, 268,   6],\n",
       "       [115,  64, 147,  96,   2],\n",
       "       [244, 324, 263, 370,  18],\n",
       "       [ 80, 176, 108, 212,   3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.load_annotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup a few callbacks and start the training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:15.714460Z",
     "start_time": "2017-11-26T12:38:15.708674Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T20:38:54.037Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 870s 3s/step - loss: 10.3148 - val_loss: 3.6099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.60992, saving model to weights_coco.h5\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 3.3019 - val_loss: 3.2523\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.60992 to 3.25227, saving model to weights_coco.h5\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 3.9337 - val_loss: 3.1458\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.25227 to 3.14576, saving model to weights_coco.h5\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 3.0432 - val_loss: 2.9946\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.14576 to 2.99463, saving model to weights_coco.h5\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.9614 - val_loss: 2.9306\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.99463 to 2.93059, saving model to weights_coco.h5\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.9124 - val_loss: 2.8945\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.93059 to 2.89448, saving model to weights_coco.h5\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.8790 - val_loss: 2.8564\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.89448 to 2.85638, saving model to weights_coco.h5\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.8492 - val_loss: 2.8326\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.85638 to 2.83258, saving model to weights_coco.h5\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.8268 - val_loss: 2.8166\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.83258 to 2.81663, saving model to weights_coco.h5\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.8082 - val_loss: 2.7917\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.81663 to 2.79174, saving model to weights_coco.h5\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 848s 3s/step - loss: 2.7868 - val_loss: 2.7769\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.79174 to 2.77691, saving model to weights_coco.h5\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 845s 3s/step - loss: 2.7767 - val_loss: 2.7673\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.77691 to 2.76734, saving model to weights_coco.h5\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.7632 - val_loss: 2.7544\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.76734 to 2.75441, saving model to weights_coco.h5\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.7518 - val_loss: 2.7365\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.75441 to 2.73647, saving model to weights_coco.h5\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.7377 - val_loss: 2.7310\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.73647 to 2.73099, saving model to weights_coco.h5\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.7278 - val_loss: 2.7214\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.73099 to 2.72139, saving model to weights_coco.h5\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 2.7148 - val_loss: 2.7117\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.72139 to 2.71165, saving model to weights_coco.h5\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.7115 - val_loss: 2.6997\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.71165 to 2.69968, saving model to weights_coco.h5\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.7008 - val_loss: 2.6927\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.69968 to 2.69267, saving model to weights_coco.h5\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.6918 - val_loss: 2.6835\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.69267 to 2.68350, saving model to weights_coco.h5\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 859s 3s/step - loss: 2.6818 - val_loss: 2.6777\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.68350 to 2.67767, saving model to weights_coco.h5\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 858s 3s/step - loss: 2.6734 - val_loss: 2.6609\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.67767 to 2.66093, saving model to weights_coco.h5\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 2.6578 - val_loss: 2.6496\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.66093 to 2.64960, saving model to weights_coco.h5\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.6466 - val_loss: 2.6427\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.64960 to 2.64265, saving model to weights_coco.h5\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.6286 - val_loss: 2.6183\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.64265 to 2.61835, saving model to weights_coco.h5\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 2.6094 - val_loss: 2.6022\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.61835 to 2.60218, saving model to weights_coco.h5\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 842s 3s/step - loss: 2.5817 - val_loss: 2.5576\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.60218 to 2.55755, saving model to weights_coco.h5\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.5485 - val_loss: 2.5271\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.55755 to 2.52714, saving model to weights_coco.h5\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.4999 - val_loss: 2.4679\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.52714 to 2.46795, saving model to weights_coco.h5\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 2.4479 - val_loss: 2.4120\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.46795 to 2.41197, saving model to weights_coco.h5\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 855s 3s/step - loss: 2.3854 - val_loss: 2.3457\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.41197 to 2.34571, saving model to weights_coco.h5\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 859s 3s/step - loss: 2.2995 - val_loss: 2.2889\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.34571 to 2.28889, saving model to weights_coco.h5\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 848s 3s/step - loss: 2.2186 - val_loss: 2.1674\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.28889 to 2.16736, saving model to weights_coco.h5\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 2.1481 - val_loss: 2.0938\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.16736 to 2.09384, saving model to weights_coco.h5\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 2.0524 - val_loss: 2.0315\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.09384 to 2.03147, saving model to weights_coco.h5\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 843s 3s/step - loss: 1.9745 - val_loss: 1.9248\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.03147 to 1.92483, saving model to weights_coco.h5\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 846s 3s/step - loss: 1.8850 - val_loss: 1.8549\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.92483 to 1.85491, saving model to weights_coco.h5\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.7909 - val_loss: 1.7436\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.85491 to 1.74356, saving model to weights_coco.h5\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.7325 - val_loss: 1.6843\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.74356 to 1.68430, saving model to weights_coco.h5\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 843s 3s/step - loss: 1.6335 - val_loss: 1.6073\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.68430 to 1.60725, saving model to weights_coco.h5\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 853s 3s/step - loss: 1.5509 - val_loss: 1.5106\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.60725 to 1.51055, saving model to weights_coco.h5\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 1.4698 - val_loss: 1.4468\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.51055 to 1.44680, saving model to weights_coco.h5\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 851s 3s/step - loss: 1.4228 - val_loss: 1.3858\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.44680 to 1.38582, saving model to weights_coco.h5\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 854s 3s/step - loss: 1.3504 - val_loss: 1.3628\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.38582 to 1.36276, saving model to weights_coco.h5\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.3162 - val_loss: 1.2648\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.36276 to 1.26479, saving model to weights_coco.h5\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 1.2528 - val_loss: 1.2270\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.26479 to 1.22704, saving model to weights_coco.h5\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.2128 - val_loss: 1.1864\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.22704 to 1.18644, saving model to weights_coco.h5\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 849s 3s/step - loss: 1.1598 - val_loss: 1.1605\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.18644 to 1.16047, saving model to weights_coco.h5\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 1.1296 - val_loss: 1.1270\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.16047 to 1.12698, saving model to weights_coco.h5\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.0778 - val_loss: 1.1063\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.12698 to 1.10630, saving model to weights_coco.h5\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 847s 3s/step - loss: 1.0669 - val_loss: 1.1260\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 1.0154 - val_loss: 1.0176\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.10630 to 1.01762, saving model to weights_coco.h5\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 850s 3s/step - loss: 0.9857 - val_loss: 1.0172\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.01762 to 1.01721, saving model to weights_coco.h5\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 852s 3s/step - loss: 127.9096 - val_loss: nan\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 855s 3s/step - loss: 2.8633 - val_loss: 5.1818\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c28039f60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = os.path.expanduser('~/Workspaces/DeepCalculatorBot/ObjectDetection/logs/')\n",
    "tb_counter  = len([log for log in os.listdir(log_dir) if 'coco_' in log]) + 1\n",
    "tensorboard = TensorBoard(log_dir=os.path.expanduser(log_dir) + 'coco_' + '_' + str(tb_counter), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_images=True)\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform detection on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:49.271978Z",
     "start_time": "2017-11-22T14:07:49.268999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:19:07.263359",
     "start_time": "2018-04-04T00:19:05.658285"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = cv2.imread('/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/fake_dataset/features/52.png')\n",
    "# image = cv2.imread('/home/jacopo.gasparetto/Workspaces/DeepCalculatorBot/ObjectDetection/test_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "print(image.shape)\n",
    "input_image = cv2.resize(image, (416, 416))\n",
    "input_image = input_image / 255.\n",
    "input_image = input_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "netout = model.predict([input_image, dummy_array])\n",
    "boxes = decode_netout(netout[0], \n",
    "                      obj_threshold=OBJ_THRESHOLD,\n",
    "                      nms_threshold=NMS_THRESHOLD,\n",
    "                      anchors=ANCHORS, \n",
    "                      nb_class=CLASS)\n",
    "image = draw_boxes(image, boxes, labels=LABELS)\n",
    "\n",
    "plt.imshow(image[:,:,::-1]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
